<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>vexcl: VexCL</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />



</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">vexcl
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.8.0 -->
<script type="text/javascript" src="dynsections.js"></script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">VexCL </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>VexCL is vector expression template library for OpenCL. It has been created for ease of C++ based OpenCL development. Multi-device (and multi-platform) computations are supported. The source code is available at <a href="https://github.com/ddemidov/vexcl">https://github.com/ddemidov/vexcl</a>.</p>
<h2><a class="anchor" id="devlist"></a>
Selection of compute devices</h2>
<p>You can select any number of available compute devices, which satisfy provided filters. Filter is a functor returning bool and acting on a cl::Device parameter. Several standard filters are provided, such as device type or name filter, double precision support etc. Filters can be combined with logical operators. In the example below all devices with names matching "Radeon" and supporting double precision are selected: </p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include &lt;<a class="code" href="vexcl_8hpp.html" title="Vector expression template library for OpenCL.">vexcl/vexcl.hpp</a>&gt;</span>
<span class="keyword">using namespace </span>vex;
<span class="keywordtype">int</span> main() {
    <span class="keyword">auto</span> device = <a class="code" href="namespacevex.html#a91041b9b4ad749b9d4ef7de0a29b16e4" title="Select devices by given criteria.">device_list</a>(
        <a class="code" href="structvex_1_1Filter_1_1Name.html" title="Selects devices whose names match given value.">Filter::Name</a>(<span class="stringliteral">&quot;Radeon&quot;</span>) &amp;&amp; <a class="code" href="structvex_1_1Filter_1_1DoublePrecision.html" title="Selects devices supporting double precision.">Filter::DoublePrecision</a>()
        );
    std::cout &lt;&lt; device &lt;&lt; std::endl;
}
</pre></div><p>Often you want not just device list, but initialized OpenCL context with command queue on each available device. This may be achieved with <a class="el" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list()</a> function: </p>
<div class="fragment"><pre class="fragment">cl::Context context;
std::vector&lt;cl::CommandQueue&gt; queue;
<span class="comment">// Select no more than 2 NVIDIA GPUs:</span>
std::tie(context, queue) = <a class="code" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list</a>(
    [](<span class="keyword">const</span> cl::Device &amp;d) {
        <span class="keywordflow">return</span> d.getInfo&lt;CL_DEVICE_VENDOR&gt;() == <span class="stringliteral">&quot;NVIDIA Corporation&quot;</span>;
    } &amp;&amp; Filter::Count(2)
    );
</pre></div><h2><a class="anchor" id="vector"></a>
Memory allocation and vector arithmetic</h2>
<p>Once you got queue list, you can allocate OpenCL buffers on the associated devices. <a class="el" href="classvex_1_1vector.html" title="Device vector.">vex::vector</a> constructor accepts std::vector of cl::CommandQueue. The contents of the created vector will be equally partitioned between each queue (presumably, each of the provided queues is linked with separate device). Size of each partition will be proportional to relative device bandwidth unless macro VEXCL_DUMB_PARTITIONING is defined, in which case equal partitioning scheme will be applied. Device bandwidth is measured first time it is requested by launch of small test kernel.</p>
<p>Multi-platform computation is supported (that is, you can spread your vectors across devices by different vendors), but should be used with caution: all computations will be performed with the speed of the slowest device selected.</p>
<p>In the example below host vector is allocated and initialized, then copied to all devices obtained with the <a class="el" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list()</a> call. A couple of empty device vectors are allocated as well: </p>
<div class="fragment"><pre class="fragment"><span class="keyword">const</span> uint n = 1 &lt;&lt; 20;
std::vector&lt;double&gt; x(n);
std::generate(x.begin(), x.end(), [](){ <span class="keywordflow">return</span> (<span class="keywordtype">double</span>)rand() / RAND_MAX; });

cl::Context context;
std::vector&lt;cl::CommandQueue&gt; queue;
std::tie(context, queue) = <a class="code" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list</a>(Filter::Type(CL_DEVICE_TYPE_GPU));

<a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> X(queue, CL_MEM_READ_ONLY,  x);
<a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> Y(queue, CL_MEM_READ_WRITE, n);
<a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> Z(queue, CL_MEM_READ_WRITE, n);
</pre></div><p>You can now use simple vector arithmetic with device vector. For every expression you use, appropriate kernel is compiled (first time it is encountered in your program) and called automagically.</p>
<p>Vectors are processed in parallel across all devices they were allocated on: </p>
<div class="fragment"><pre class="fragment">Y = <a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(42);
Z = sqrt(<a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(2) * X) + cos(Y);
</pre></div><p>You can copy the result back to host or you can use vector::operator[] to read (or write) vector elements directly. Though latter technique is very ineffective and should be used for debugging purposes only. </p>
<div class="fragment"><pre class="fragment"><a class="code" href="namespacevex.html#a7896b8bc121f843d62d724a98ebe3b46" title="Copy device vector to host vector.">copy</a>(Z, x);
assert(x[42] == Z[42]);
</pre></div><p>Another frequently performed operation is reduction of a vector expression to single value, such as summation. This can be done with <a class="el" href="classvex_1_1Reductor.html" title="Parallel reduction of arbitrary expression.">vex::Reductor</a> class: </p>
<div class="fragment"><pre class="fragment">Reductor&lt;double&gt; sum(queue);

std::cout &lt;&lt; sum(Z) &lt;&lt; std::endl;
std::cout &lt;&lt; sum(sqrt(<a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(2) * X) + cos(Y)) &lt;&lt; std::endl;
</pre></div><h2><a class="anchor" id="spmv"></a>
Sparse matrix-vector multiplication</h2>
<p>One of the most common operations in linear algebra is matrix-vector multiplication. Class <a class="el" href="classvex_1_1SpMat.html" title="Sparse matrix.">vex::SpMat</a> holds representation of a sparse matrix, spanning several devices. In the example below it is used for solution of a system of linear equations with conjugate gradients method: </p>
<div class="fragment"><pre class="fragment"><span class="keyword">typedef</span> <span class="keywordtype">double</span> real;
<span class="comment">// Solve system of linear equations A u = f with conjugate gradients method.</span>
<span class="comment">// Input matrix is represented in CSR format (parameters row, col, and val).</span>
<span class="keywordtype">void</span> cg_gpu(
        <span class="keyword">const</span> std::vector&lt;uint&gt; &amp;row,   <span class="comment">// Indices to col and val vectors.</span>
        <span class="keyword">const</span> std::vector&lt;uint&gt; &amp;col,   <span class="comment">// Column numbers of non-zero elements.</span>
        <span class="keyword">const</span> std::vector&lt;real&gt; &amp;val,   <span class="comment">// Values of non-zero elements.</span>
        <span class="keyword">const</span> std::vector&lt;real&gt; &amp;rhs,   <span class="comment">// Right-hand side.</span>
        std::vector&lt;real&gt; &amp;x            <span class="comment">// In: initial approximation; out: result.</span>
        )
{
    <span class="comment">// Init OpenCL.</span>
    cl::Context context;
    std::vector&lt;cl::CommandQueue&gt; queue;

    std::tie(context, queue) = <a class="code" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list</a>(Filter::Type(CL_DEVICE_TYPE_GPU));

    <span class="comment">// Move data to compute devices.</span>
    uint n = x.size();
    <a class="code" href="classvex_1_1SpMat.html" title="Sparse matrix.">vex::SpMat&lt;real&gt;</a>  A(queue, n, row.data(), col.data(), val.data());
    <a class="code" href="classvex_1_1vector.html">vex::vector&lt;real&gt;</a> f(queue, CL_MEM_READ_ONLY,  rhs);
    <a class="code" href="classvex_1_1vector.html">vex::vector&lt;real&gt;</a> u(queue, CL_MEM_READ_WRITE, x);
    <a class="code" href="classvex_1_1vector.html">vex::vector&lt;real&gt;</a> r(queue, CL_MEM_READ_WRITE, n);
    <a class="code" href="classvex_1_1vector.html">vex::vector&lt;real&gt;</a> p(queue, CL_MEM_READ_WRITE, n);
    <a class="code" href="classvex_1_1vector.html">vex::vector&lt;real&gt;</a> q(queue, CL_MEM_READ_WRITE, n);

    Reductor&lt;real,MAX&gt; max(queue);
    Reductor&lt;real,SUM&gt; sum(queue);

    <span class="comment">// Solve equation Au = f with conjugate gradients method.</span>
    real rho1, rho2;
    r = f - A * u;

    <span class="keywordflow">for</span>(uint iter = 0; max(Abs(r)) &gt; 1e-8 &amp;&amp; iter &lt; n; iter++) {
        rho1 = sum(r * r);

        <span class="keywordflow">if</span> (iter == 0) {
            p = r;
        } <span class="keywordflow">else</span> {
            real beta = rho1 / rho2;
            p = r + <a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(beta) * p;
        }

        q = A * p;

        real alpha = rho1 / sum(p * q);

        u += <a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(alpha) * p;
        r -= <a class="code" href="namespacevex.html#a53f74439e6dca489cb5fe5af5a911685" title="Constant for use in vector expressions.">Const</a>(alpha) * q;

        rho2 = rho1;
    }

    <span class="comment">// Get result to host.</span>
    <a class="code" href="namespacevex.html#a7896b8bc121f843d62d724a98ebe3b46" title="Copy device vector to host vector.">copy</a>(u, x);
}
</pre></div><h2><a class="anchor" id="custkern"></a>
Using custom kernels</h2>
<p>Custom kernels are of course possible as well. vector::operator(uint) returns cl::Buffer object for a specified device: </p>
<div class="fragment"><pre class="fragment">cl::Context context;
std::vector&lt;cl::CommandQueue&gt; queue;
std::tie(context, queue) = <a class="code" href="namespacevex.html#ad5a7fdbec637a7a896600280b175912a" title="Create command queues on devices by given criteria.">queue_list</a>(Filter::Type(CL_DEVICE_TYPE_GPU));

<span class="keyword">const</span> uint n = 1 &lt;&lt; 20;
<a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;float&gt;</a> x(queue, CL_MEM_WRITE_ONLY, n);

<span class="keyword">auto</span> program = <a class="code" href="namespacevex.html#a61989abf337d9845cad96ce9e805fd56" title="Create and build a program from source string.">build_sources</a>(context, std::string(
    <span class="stringliteral">&quot;kernel void dummy(uint size, global float *x)\n&quot;</span>
    <span class="stringliteral">&quot;{\n&quot;</span>
    <span class="stringliteral">&quot;    uint i = get_global_id(0);\n&quot;</span>
    <span class="stringliteral">&quot;    if (i &lt; size) x[i] = 4.2;\n&quot;</span>
    <span class="stringliteral">&quot;}\n&quot;</span>
    ));

<span class="keywordflow">for</span>(uint d = 0; d &lt; queue.size(); d++) {
    <span class="keyword">auto</span> dummy = cl::Kernel(program, <span class="stringliteral">&quot;dummy&quot;</span>).bind(queue[d], <a class="code" href="namespacevex.html#a8c39134f49eb496e0b2bdaf3d3e1cea1" title="Align n to the next multiple of m.">alignup</a>(n, 256), 256);
    dummy((uint)x.part_size(d), x(d));
}

Reductor&lt;float,SUM&gt; sum(queue);
std::cout &lt;&lt; sum(x) &lt;&lt; std::endl;
</pre></div><h2><a class="anchor" id="scalability"></a>
Scalability</h2>
<p>In the images below, scalability of the library with respect to number of compute devices is shown. Effective performance (GFLOPS) and bandwidth (GB/sec) were measured by launching big number of test kernels on one, two, or three Nvidia Tesla C2070 cards. The results shown are averaged over 20 runs.</p>
<p>The details of the experiments may be found in <a href="https://github.com/ddemidov/vexcl/blob/master/examples/profiling.cpp">examples/profiling.cpp</a> file. Basically, performance of the following code was measured:</p>
<div class="fragment"><pre class="fragment"><span class="comment">// Vector arithmetic</span>
a += b + c * d;

<span class="comment">// Reduction</span>
<span class="keywordtype">double</span> s = sum(a * b);

<span class="comment">// SpMV</span>
y += A * x;
</pre></div><div class="image">
<img src="perf.png" alt="perf.png"/>
</div>
</div></div><!-- contents -->


<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.0
</small></address>

</body>
</html>
