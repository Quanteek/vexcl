<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>VexCL: VexCL</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">VexCL
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.2 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">VexCL </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>VexCL is vector expression template library for OpenCL. It has been created for ease of OpenCL developement with C++. VexCL strives to reduce amount of boilerplate code needed to develop OpenCL applications. The library provides convenient and intuitive notation for vector arithmetic, reduction, and sparse matrix-vector multiplication. Multi-device and even multi-platform computations are supported. The source code is available at <a href="https://github.com/ddemidov/vexcl">https://github.com/ddemidov/vexcl</a>.</p>
<h1><a class="anchor" id="devlist"></a>
Selection of compute devices</h1>
<p>You can select any number of available compute devices, which satisfy provided filters. Filter is a functor returning bool and acting on a cl::Device parameter. Several standard filters are provided, such as device type or name filter, double precision support etc. Filters can be combined with logical operators. In the example below all devices with names matching "Radeon" and supporting double precision are selected: </p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="vexcl_8hpp.html" title="Vector expression template library for OpenCL.">vexcl/vexcl.hpp</a>&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>vex;</div>
<div class="line"><span class="keywordtype">int</span> main() {</div>
<div class="line">    <a class="code" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> ctx(<a class="code" href="structvex_1_1Filter_1_1Name.html" title="Selects devices whose names match given value.">Filter::Name</a>(<span class="stringliteral">&quot;Radeon&quot;</span>) &amp;&amp; Filter::DoublePrecision);</div>
<div class="line">    std::cout &lt;&lt; ctx &lt;&lt; std::endl;</div>
<div class="line">}</div>
</div><!-- fragment --><p> <a class="el" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> object holds list of initialized OpenCL contexts and command queues for each filtered device. If you just need list of available devices without creating contexts and queues on them, then look for <a class="el" href="namespacevex.html#a0571bb5e0afbc53f844665652a204b0a" title="Select devices by given criteria.">device_list()</a> function in documenation.</p>
<p>If you wish to obtain exclusive access to your devices (across all processes that use VexCL library), just wrap your device filter in <a class="el" href="namespacevex_1_1Filter.html#a0664aab5022fab0f7764d0e72cb06fc8" title="Allows exclusive access to compute devices across several processes.">Filter::Exclusive()</a> function call: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> ctx( <a class="code" href="namespacevex_1_1Filter.html#a0664aab5022fab0f7764d0e72cb06fc8" title="Allows exclusive access to compute devices across several processes.">Filter::Exclusive</a>( Filter::Platform(<span class="stringliteral">&quot;NVIDIA&quot;</span>) &amp;&amp; Filter::DoublePrecision ) );</div>
</div><!-- fragment --><h1><a class="anchor" id="vector"></a>
Memory allocation and vector arithmetic</h1>
<p>Once you got queue list, you can allocate OpenCL buffers on the associated devices. <a class="el" href="classvex_1_1vector.html" title="Device vector.">vex::vector</a> constructor accepts std::vector of cl::CommandQueue. The contents of the created vector will be partitioned between each queue (presumably, each of the provided queues is linked with separate device). Size of each partition will be proportional to relative device bandwidth. Device bandwidth is measured first time it is requested by launch of small test kernel.</p>
<p>Multi-platform computation is supported (that is, you can spread your vectors across devices by different vendors), but should be used with caution: all computations will be performed with the speed of the slowest device selected.</p>
<p>In the example below host vector is allocated and initialized, then copied to all GPU devices found in the system. A couple of empty device vectors are allocated as well: </p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1 &lt;&lt; 20;</div>
<div class="line">std::vector&lt;double&gt; x(n);</div>
<div class="line">std::generate(x.begin(), x.end(), [](){ <span class="keywordflow">return</span> (<span class="keywordtype">double</span>)rand() / RAND_MAX; });</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> ctx(Filter::Type(CL_DEVICE_TYPE_GPU));</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> X(ctx.queue(), x);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> Y(ctx.queue(), n);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> Z(ctx.queue(), n);</div>
</div><!-- fragment --><p>You can now use simple vector arithmetic with device vector. For every expression you use, appropriate kernel is compiled (first time it is encountered in your program) and called automagically. If you want to see sources of the generated kernels on the standard output, define VEXCL_SHOW_KERNELS macro before including VexCL headers.</p>
<p>Vectors are processed in parallel across all devices they were allocated on: </p>
<div class="fragment"><div class="line">Y = 42;</div>
<div class="line">Z = sqrt(2 * X) + cos(Y);</div>
</div><!-- fragment --><p>You can copy the result back to host or you can use vector::operator[] to read (or write) vector elements directly. Though latter technique is very ineffective and should be used for debugging purposes only. </p>
<div class="fragment"><div class="line"><a class="code" href="namespacevex.html#a4d23fe6f2794c7738f6948358afc5068" title="Copy multivector to host vector.">copy</a>(Z, x);</div>
<div class="line">assert(x[42] == Z[42]);</div>
</div><!-- fragment --><p>Another frequently performed operation is reduction of a vector expression to single value, such as summation. This can be done with <a class="el" href="classvex_1_1Reductor.html" title="Parallel reduction of arbitrary expression.">vex::Reductor</a> class: </p>
<div class="fragment"><div class="line">Reductor&lt;double&gt; sum(ctx.queue());</div>
<div class="line"></div>
<div class="line">std::cout &lt;&lt; sum(Z) &lt;&lt; std::endl;</div>
<div class="line">std::cout &lt;&lt; sum(sqrt(2 * X) + cos(Y)) &lt;&lt; std::endl;</div>
</div><!-- fragment --><h1><a class="anchor" id="stencil"></a>
Stencil convolution</h1>
<p>Stencil convolution operation comes in handy in many situations. For example, it allows us to apply a moving average filter to a device vector. All you need is to construct a <a class="el" href="classvex_1_1stencil.html" title="Stencil.">vex::stencil</a> object: </p>
<div class="fragment"><div class="line"><span class="comment">// Moving average with 5-points window.</span></div>
<div class="line">std::vector&lt;double&gt; sdata(5, 0.2);</div>
<div class="line">stencil(ctx.queue(), sdata, sdata.size() / 2);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> x(ctx.queue(), 1024 * 1024);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> y(ctx.queue(), 1024 * 1024);</div>
<div class="line"></div>
<div class="line">x = 1;</div>
<div class="line">y = x * s; <span class="comment">// convolve x with s</span></div>
</div><!-- fragment --><h1><a class="anchor" id="spmv"></a>
Sparse matrix-vector multiplication</h1>
<p>One of the most common operations in linear algebra is matrix-vector multiplication. Class <a class="el" href="classvex_1_1SpMat.html" title="Sparse matrix in hybrid ELL-CSR format.">vex::SpMat</a> holds representation of a sparse matrix, spanning several devices. In the example below it is used for solution of a system of linear equations with conjugate gradients method: </p>
<div class="fragment"><div class="line"><span class="keyword">typedef</span> <span class="keywordtype">double</span> real;</div>
<div class="line"><span class="comment">// Solve system of linear equations A u = f with conjugate gradients method.</span></div>
<div class="line"><span class="comment">// Input matrix is represented in CSR format (parameters row, col, and val).</span></div>
<div class="line"><span class="keywordtype">void</span> cg_gpu(</div>
<div class="line">        <span class="keyword">const</span> std::vector&lt;size_t&gt; &amp;row, <span class="comment">// Indices to col and val vectors.</span></div>
<div class="line">        <span class="keyword">const</span> std::vector&lt;size_t&gt; &amp;col, <span class="comment">// Column numbers of non-zero elements.</span></div>
<div class="line">        <span class="keyword">const</span> std::vector&lt;real&gt;   &amp;val, <span class="comment">// Values of non-zero elements.</span></div>
<div class="line">        <span class="keyword">const</span> std::vector&lt;real&gt;   &amp;rhs, <span class="comment">// Right-hand side.</span></div>
<div class="line">        std::vector&lt;real&gt; &amp;x            <span class="comment">// In: initial approximation; out: result.</span></div>
<div class="line">        )</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Init OpenCL.</span></div>
<div class="line">    <a class="code" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> ctx(Filter::Type(CL_DEVICE_TYPE_GPU));</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Move data to compute devices.</span></div>
<div class="line">    <span class="keywordtype">size_t</span> n = x.size();</div>
<div class="line">    <a class="code" href="classvex_1_1SpMat.html" title="Sparse matrix in hybrid ELL-CSR format.">vex::SpMat&lt;real&gt;</a>  A(ctx.queue(), n, n, row.data(), col.data(), val.data());</div>
<div class="line">    <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;real&gt;</a> f(ctx.queue(), rhs);</div>
<div class="line">    <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;real&gt;</a> u(ctx.queue(), x);</div>
<div class="line">    <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;real&gt;</a> r(ctx.queue(), n);</div>
<div class="line">    <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;real&gt;</a> p(ctx.queue(), n);</div>
<div class="line">    <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;real&gt;</a> q(ctx.queue(), n);</div>
<div class="line"></div>
<div class="line">    Reductor&lt;real,MAX&gt; max(ctx.queue());</div>
<div class="line">    Reductor&lt;real,SUM&gt; sum(ctx.queue());</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Solve equation Au = f with conjugate gradients method.</span></div>
<div class="line">    real rho1, rho2;</div>
<div class="line">    r = f - A * u;</div>
<div class="line"></div>
<div class="line">    <span class="keywordflow">for</span>(uint iter = 0; max(fabs(r)) &gt; 1e-8 &amp;&amp; iter &lt; n; iter++) {</div>
<div class="line">        rho1 = sum(r * r);</div>
<div class="line"></div>
<div class="line">        <span class="keywordflow">if</span> (iter == 0) {</div>
<div class="line">            p = r;</div>
<div class="line">        } <span class="keywordflow">else</span> {</div>
<div class="line">            real beta = rho1 / rho2;</div>
<div class="line">            p = r + beta * p;</div>
<div class="line">        }</div>
<div class="line"></div>
<div class="line">        q = A * p;</div>
<div class="line"></div>
<div class="line">        real alpha = rho1 / sum(p * q);</div>
<div class="line"></div>
<div class="line">        u += alpha * p;</div>
<div class="line">        r -= alpha * q;</div>
<div class="line"></div>
<div class="line">        rho2 = rho1;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Get result to host.</span></div>
<div class="line">    <a class="code" href="namespacevex.html#a4d23fe6f2794c7738f6948358afc5068" title="Copy multivector to host vector.">copy</a>(u, x);</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="userfun"></a>
User-defined functions</h1>
<p>Simple arithmetic expressions are sometimes not enough. Imagine that you need to count how many elements in vector x are greater that their counterparts in vector y. This may be achieved by introduction of custom function. In order to build such a function, you need to supply its body, its return type and types of its arguments. After that, you can apply the function to any valid vector expressions: </p>
<div class="fragment"><div class="line"><span class="comment">// Function body has to be defined at global scope, and it has to be of `extern</span></div>
<div class="line"><span class="comment">// const char[]` type. This allows us to use it as a template parameter.</span></div>
<div class="line"><span class="keyword">extern</span> <span class="keyword">const</span> <span class="keywordtype">char</span> greater_body[] = <span class="stringliteral">&quot;return prm1 &gt; prm2 ? 1 : 0;&quot;</span>;</div>
<div class="line">UserFunction&lt;greater_body, size_t(float, float)&gt; greater;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">size_t</span> count_if_greater(</div>
<div class="line">    <span class="keyword">const</span> Reductor&lt;size_t, SUM&gt; &amp;sum,</div>
<div class="line">    <span class="keyword">const</span> <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;float&gt;</a> &amp;x,</div>
<div class="line">    <span class="keyword">const</span> <a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;float&gt;</a> &amp;y</div>
<div class="line">    )</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">return</span> sum(greater(x, y));</div>
<div class="line">}</div>
</div><!-- fragment --><p>You could also write sum(greater(x + y, 5 * y)), or use any other expressions as parameters to the greater() call. Note that in the function body parameters are always named as prm1, prm2, etc.</p>
<h1><a class="anchor" id="multivector"></a>
Multi-component vectors</h1>
<p>Class template vex::multivector&lt;T,N&gt; allows to store several equally sized device vectors and perform computations on all components synchronously. Operations are delegated to the underlying vectors. Expressions may include std::array&lt;T,N&gt; values, where N is equal to the number of multivector components. Each component gets corresponding element of std::array&lt;&gt; when expression is applied. </p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1 &lt;&lt; 20;</div>
<div class="line">std::vector&lt;double&gt; host(n * 3);</div>
<div class="line">std::generate(host.begin(), host.end(), rand);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1multivector.html" title="Container for several vex::vectors.">vex::multivector&lt;double,3&gt;</a> x(ctx.queue(), host);</div>
<div class="line"><a class="code" href="classvex_1_1multivector.html" title="Container for several vex::vectors.">vex::multivector&lt;double,3&gt;</a> y(ctx.queue(), n);</div>
<div class="line"></div>
<div class="line">std::array&lt;int, 3&gt; c = {4, 5, 6};</div>
<div class="line"></div>
<div class="line">y = 2 * cos(x) - c;</div>
<div class="line"></div>
<div class="line">std::array&lt;double,3&gt; v = y[42];</div>
<div class="line">assert(fabs(v[1] - (2 * cos(host[n + 42]) - c[1])) &lt; 1e-8);</div>
</div><!-- fragment --><p>Components of a multivector may be accessed with operator(): </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> z = y(1);</div>
</div><!-- fragment --><p>Sometimes operations with multicomponent vector cannot be expressed with simple arithmetic expressions. Imagine that you need to solve the following system of ordinary differential equations: </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \frac{dx}{dt} = x + y, \quad \frac{dy}{dt} = x - y. \]" src="form_0.png"/>
</p>
<p>If the system state is represented as vex::multivector&lt;double,2&gt;, then the system function for this ODE could be implemented as </p>
<div class="fragment"><div class="line"><span class="comment">// vex::multivector&lt;double,2&gt; dxdt, x;</span></div>
<div class="line">dxdt(0) = x(0) + x(1);</div>
<div class="line">dxdt(1) = x(0) - x(1);</div>
</div><!-- fragment --><p>This results in two kernel launches. Instead, you can use the following form: </p>
<div class="fragment"><div class="line">dxdt = <a class="code" href="namespacevex.html#a1f12df83605db6011463d6bca2b584ca" title="Ties several vex::vectors into a multivector.">std::tie</a>(x(0) + x(1), x(0) - x(1));</div>
</div><!-- fragment --><p> This expression would generate and launch single combined kernel, which would be more effective. Multi-expressions like these may also be used with ordinary vex::vectors with help of <a class="el" href="namespacevex.html#a1f12df83605db6011463d6bca2b584ca" title="Ties several vex::vectors into a multivector.">vex::tie()</a> function: </p>
<div class="fragment"><div class="line"><span class="comment">// vex::vector&lt;double&gt; dx, dy, x, y;</span></div>
<div class="line"><a class="code" href="namespacevex.html#a1f12df83605db6011463d6bca2b584ca" title="Ties several vex::vectors into a multivector.">vex::tie</a>(dx,dy) = <a class="code" href="namespacevex.html#a1f12df83605db6011463d6bca2b584ca" title="Ties several vex::vectors into a multivector.">std::tie</a>(x + y, x - y);</div>
</div><!-- fragment --><h1><a class="anchor" id="kernel_generator"></a>
Converting existing algorithms to kernels</h1>
<p>VexCL kernel generator allows to transparently convert existing CPU algorithm to an OpenCL kernel. In order to do this you need to record sequence of arithmetic expressions made by an algorithm and convert the recorded sequence to a kernel. The recording part is done with help of vex::generator::symbolic&lt;T&gt; class. The class supports arithmetic expression templates and simply outputs to provided stream any expressions it is being subjected to.</p>
<p>To illustrate this, imagine that you have generic algorithm for a 4th order Runge-Kutta ODE stepper:</p>
<div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> state_type, <span class="keyword">class</span> SysFunction&gt;</div>
<div class="line"><span class="keywordtype">void</span> runge_kutta_4(SysFunction sys, state_type &amp;x, <span class="keywordtype">double</span> dt) {</div>
<div class="line">    state_type xtmp, k1, k2, k3, k4;</div>
<div class="line"></div>
<div class="line">    sys(x, k1, dt);</div>
<div class="line"></div>
<div class="line">    xtmp = x + 0.5 * k1;</div>
<div class="line">    sys(xtmp, k2, dt);</div>
<div class="line"></div>
<div class="line">    xtmp = x + 0.5 * k2;</div>
<div class="line">    sys(xtmp, k3, dt);</div>
<div class="line"></div>
<div class="line">    xtmp = x + k3;</div>
<div class="line">    sys(xtmp, k4, dt);</div>
<div class="line"></div>
<div class="line">    x += (k1 + 2 * k2 + 2 * k3 + k4) / 6;</div>
<div class="line">}</div>
</div><!-- fragment --><p> To model equation <img class="formulaInl" alt="$\frac{dx}{dt} = sin(x)$" src="form_1.png"/> we also provide the following system function: </p>
<div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> state_type&gt;</div>
<div class="line"><span class="keywordtype">void</span> sys_func(<span class="keyword">const</span> state_type &amp;x, state_type &amp;dx, <span class="keywordtype">double</span> dt) {</div>
<div class="line">    dx = dt * sin(x);</div>
<div class="line">}</div>
</div><!-- fragment --><p> Now, to make a hundred of RK4 iterations for a double value on CPU, all that we need to do is </p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> x  = 1;</div>
<div class="line"><span class="keywordtype">double</span> dt = 0.01;</div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; 100; i++)</div>
<div class="line">    runge_kutta_4(sys_func&lt;double&gt;, x, dt);</div>
</div><!-- fragment --><p> Let us now generate the kernel for single RK4 step and apply the kernel to a vex::vector&lt;double&gt; (by doing this we essentially simpultaneously solve big number of same ODEs with different initial conditions). </p>
<div class="fragment"><div class="line"><span class="comment">// Set recorder for expression sequence.</span></div>
<div class="line">std::ostringstream body;</div>
<div class="line">vex::generator::set_recorder(body);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create symbolic variable.</span></div>
<div class="line"><span class="keyword">typedef</span> vex::generator::symbolic&lt;double&gt; sym_state;</div>
<div class="line">sym_state sym_x(sym_state::VectorParameter);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Record expression sequience.</span></div>
<div class="line"><span class="keywordtype">double</span> dt = 0.01;</div>
<div class="line">runge_kutta_4(sys_func&lt;sym_state&gt;, sym_x, dt);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Build kernel.</span></div>
<div class="line"><span class="keyword">auto</span> kernel = <a class="code" href="namespacevex_1_1generator.html#adcbcddc333c7b7ce307ec4515cb83def" title="Builds kernel from recorded expression sequence and symbolic parameter list.">vex::generator::build_kernel</a>(ctx.queue(),</div>
<div class="line">    <span class="stringliteral">&quot;rk4_stepper&quot;</span>, body.str(), sym_x);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create and initialize vector of states.</span></div>
<div class="line">std::vector&lt;double&gt; xinit(n);</div>
<div class="line">std::generate(xinit.begin(), xinit.end(), drand48 );</div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a> x(ctx.queue(), xinit);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Make 100 rk4 steps.</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; 100; i++) kernel(x);</div>
</div><!-- fragment --><p>This is much more effective than (for this to work correctly we would need to slightly change sys_func): </p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; 100; i++)</div>
<div class="line">    runge_kutta_4(sys_func&lt;<a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;double&gt;</a>&gt;, x, dt);</div>
</div><!-- fragment --><p> The generated kernel is more effective because temporary values used in sys_func are now represented not as full-blown vex::vectors, but as fast register variables inside the kernel body. We have seen upto tenfold performance improvement with this technique.</p>
<h1><a class="anchor" id="custkern"></a>
Using custom kernels</h1>
<p>Custom kernels are of course possible as well. vector::operator(uint) returns cl::Buffer object for a specified device: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1Context.html" title="VexCL context holder.">vex::Context</a> ctx(Filter::Vendor(<span class="stringliteral">&quot;NVIDIA&quot;</span>));</div>
<div class="line"></div>
<div class="line">std::vector&lt; cl::Kernel &gt; dummy;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Build kernel for each of the devices in context:</span></div>
<div class="line"><span class="keywordflow">for</span>(uint d = 0; d &lt; ctx.size(); d++) {</div>
<div class="line">    cl::Program program = build_sources(ctx.context(d),</div>
<div class="line">        <span class="stringliteral">&quot;kernel void dummy(ulong size, global float *x) {\n&quot;</span></div>
<div class="line">        <span class="stringliteral">&quot;    x[get_global_id(0)] = 4.2;\n&quot;</span></div>
<div class="line">        <span class="stringliteral">&quot;}\n&quot;</span>);</div>
<div class="line">    dummy.emplace_back(program, <span class="stringliteral">&quot;dummy&quot;</span>);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate device vector.</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1 &lt;&lt; 20;</div>
<div class="line"><a class="code" href="classvex_1_1vector.html" title="Device vector.">vex::vector&lt;float&gt;</a> x(ctx.queue(), n);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Process each partition of the vector with the corresponding kernel:</span></div>
<div class="line"><span class="keywordflow">for</span>(uint d = 0; d &lt; ctx.size(); d++) {</div>
<div class="line">    dummy[d].setArg(0, static_cast&lt;cl_ulong&gt;(x.part_size(d)));</div>
<div class="line">    dummy[d].setArg(1, x(d));</div>
<div class="line"></div>
<div class="line">    ctx.queue(d).enqueueNDRangeKernel(dummy[d], cl::NullRange, x.part_size(d), cl::NullRange);</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="scalability"></a>
Scalability</h1>
<p>In the images below, scalability of the library with respect to number of compute devices is shown. Effective performance (GFLOPS) and bandwidth (GB/sec) were measured by launching big number of test kernels on one, two, or three Nvidia Tesla C2070 cards. Effect of adding fourth, slower, device (Intel Core i7) were tested as well. The results shown are averaged over 20 runs.</p>
<p>The details of the experiments may be found in <a href="https://github.com/ddemidov/vexcl/blob/master/examples/benchmark.cpp">examples/benchmark.cpp</a> file. Basically, performance of the following code was measured:</p>
<div class="fragment"><div class="line"><span class="comment">// Vector arithmetic</span></div>
<div class="line">a += b + c * d;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Reduction</span></div>
<div class="line"><span class="keywordtype">double</span> s = sum(a * b);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Stencil convolution</span></div>
<div class="line">y = x * s;</div>
<div class="line"></div>
<div class="line"><span class="comment">// SpMV</span></div>
<div class="line">y += A * x;</div>
</div><!-- fragment --><div class="image">
<img src="perf.png" alt="perf.png"/>
</div>
<p> As you can see, performance and bandwidth for stencil convolution operation are much higher than for other primitives. This is due to the fact that much faster local (shared) memory is used in this algorithm, and formulas for effective performance and bandwidth do not take this into account.</p>
<p>Another thing worth noting is overall degradation of performance after Intel CPU is added to VexCL context. The only primitive gaining speed from this addition is vector arithmetic. This is probably because performance of vector arithmetic was used as a basis for problem partitioning.</p>
<h1><a class="anchor" id="compilers"></a>
Supported compilers</h1>
<p>VexCL makes heavy use of C++11 features, so your compiler has to be modern enough. The compilers that have been tested and supported are:</p>
<ul>
<li>GCC v4.6 and higher.</li>
<li>Clang v3.1 and higher.</li>
<li>Microsoft Visual C++ 2010 and higher.</li>
</ul>
<p>VexCL uses standard OpenCL bindings for C++ from Khronos group. The cl.hpp file should be included with the OpenCL implementation on your system. If it is not there, you can download it from <a href="http://www.khronos.org/registry/cl">Kronos site</a>. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.2
</small></address>
</body>
</html>
